### Hadoop 分布式文件系统

------

[TOC]

------

HDFS：被设计成适合运行在通用硬件上的分布式文件系统。HDFS是一个高度容错性的系统，适合部署在廉价的机器上。HDFS能提供高吞吐量的数据访问，非常适合大规模数据集上的应用。HDFS放宽了一部分POSIX约束，来**实现流式读取文件系统数据**的目的。

##### 01：Namenode 和 Datanode

​	HDFS采用master/slave架构。一个HDFS集群是由一个Namenode和一定数目的Datanodes组成。

- Namenode是一个中心服务器，负责管理文件系统的名字空间(namespace)以及客户端对文件的访问。
- 集群中的Datanode一般是一个节点一个，负责管理它所在节点上的存储。HDFS暴露了文件系统的名字空间，用户能够以文件的形式在上面存储数据。从内部看，一个文件其实被分成一个或多个数据块，这些块存储在一组Datanode上。
- Namenode执行文件系统的名字空间操作，比如打开、关闭、重命名文件或目录。它也负责确定数据块到具体Datanode节点的映射。
- Datanode负责处理文件系统客户端的读写请求。在Namenode的统一调度下进行数据块的创建、删除和复制。

##### 02：文件系统的名字空间 (namespace)

- HDFS支持传统的层次型文件组织结构。用户或者应用程序可以创建目录，然后将文件保存在这些目录里；
- 可以设置HDFS保存的文件的副本数目。文件副本的数目称为文件的**副本系数**，这个信息也是由Namenode保存的。

##### 03：数据复制

- HDFS被设计成能够在一个大集群中跨机器可靠地存储超大文件。它将每个文件存储成一系列的数据块，除了最后一个，所有的数据块都是同样大小的。
- HDFS中的文件都是一次性写入的，并且严格要求在任何时候只能有一个写入者。
- Namenode全权管理数据块的复制，它周期性地从集群中的每个Datanode**接收心跳信号和块状态报告(Blockreport)**。接收到心跳信号意味着该Datanode节点工作正常。块状态报告包含了一个该Datanode上所有数据块的列表。

##### 04：副本的存放

- HDFS采用一种称为机房感知(rack-aware)的策略来改进数据的可靠性、可用性和网络带宽的利用率；
- 默认副本系数是3，HDFS的存放策略是将一个副本存放在本地机房的节点上，一个副本放在同一机房的另一个节点上，最后一个副本放在不同机房节的点上。这种策略减少了机架间的数据传输，这就提高了写操作的效率。因为数据块只放在两个（不是三个）不同的机房，所以此策略减少了读取数据时需要的网络传输总带宽。

##### 05：副本选择

- 为了降低整体的带宽消耗和读取延时，HDFS会尽量让读取程序读取离它最近的副本。如果在读取程序的同一个机房上有一个副本，那么就读取该副本。

##### 06：安全模式

- Namenode启动后会进入一个称为安全模式的特殊状态。处于安全模式的Namenode是不会进行数据块的复制的。
- Namenode接受的块状态报告中，都有一个指定的最小副本数，当Namenode检测确认某个数据块的副本数目达到这个最小值，那么该数据块就会被认为是副本安全(safely replicated)的，在一定百分比（这个参数可配置）的数据块被Namenode检测确认是安全之后（加上一个额外的30秒等待时间），Namenode将退出安全模式状态。

#####  07：通讯协议

- 所有的HDFS通讯协议都是建立在TCP/IP协议之上。客户端通过一个可配置的TCP端口连接到Namenode，通过ClientProtocol协议与Namenode交互。而Datanode使用DatanodeProtocol协议与Namenode交互。

##### 08：磁盘数据错误，心跳检测和重新复制

- 每个Datanode节点周期性地向Namenode发送心跳信号。网络割裂可能导致一部分Datanode跟Namenode失去联系。Namenode通过心跳信号的缺失来检测这一情况，并将这些近期不再发送心跳信号Datanode标记为宕机，不会再将新的IO请求发给它们。
- 任何存储在宕机Datanode上的数据将不再有效。Datanode的宕机可能会引起一些数据块的副本系数低于指定值，Namenode不断地检测这些需要复制的数据块，一旦发现就启动复制操作。
- 在下列情况下，可能需要重新复制：某个Datanode节点失效，某个副本遭到损坏，Datanode上的硬盘错误，或者文件的副本系数增大。

##### 09：元数据磁盘错误

- FsImage和Editlog是HDFS的核心数据结构。如果这些文件损坏了，整个HDFS实例都将失效。因而，Namenode可以配置成支持维护多个FsImage和Editlog的副本。任何对FsImage或者Editlog的修改，都将同步到它们的副本上。当Namenode重启的时候，它会选取最近的完整的FsImage和Editlog来使用。

##### 10：数据块

- HDFS支持文件的“一次写入多次读取”语义。一个典型的数据块大小是64MB。因而，HDFS中的文件总是按照64M被切分成不同的块，每个块尽可能地存储于不同的Datanode中。

##### 11：Staging

- 客户端创建文件的请求其实并没有立即发送给Namenode，事实上，在刚开始阶段HDFS客户端会先将文件数据**缓存到本地的一个临时文件**。应用程序的写操作被透明地重定向到这个临时文件。当这个临时文件累积的**数据量超过一个数据块的大小**，客户端才会联系Namenode。Namenode将文件名插入文件系统的层次结构中，并且分配一个数据块给它。然后**返回Datanode的标识符和目标数据块给客户端**。接着客户端将这块数据从本地**临时文件上传到指定的Datanode上**。当文件关闭时，在临时文件中剩余的没有上传的数据也会传输到指定的Datanode上。然后客户端告诉Namenode文件已经关闭。此时Namenode才将文件创建操作提交到日志里进行存储。如果Namenode在文件关闭前宕机了，则该文件将丢失。

##### 12：流水线复制

- 当本地临时文件累积到一个数据块的大小时，客户端会从**Namenode获取一个Datanode列表**用于存放副本。
- 客户端开始向第一个Datanode传输数据，第一个Datanode一小部分一小部分(4 KB)地接收数据，将每一部分写入本地仓库，并同时传输该部分到列表中第二个Datanode节点。第二个Datanode也是这样，一小部分一小部分地接收数据，写入本地仓库，并同时传给第三个Datanode。最后，第三个Datanode接收数据并存储在本地。因此，Datanode能流水线式地从前一个节点接收数据，并在同时转发给下一个节点，数据以流水线的方式从前一个Datanode复制到下一个。

##### 13：DFSShell

- 提供了一个命令行的接口(DFSShell)让用户与HDFS中的数据进行交互，命令和linux命令类似；
- dfs -mkdir /dir
  - 创建目录；
- dfs -du -h filename
  - 查看文件大小；

##### 14：浏览器接口

- 典型的HDFS安装会在一个可配置的TCP端口**开启一个Web服务器用于暴露HDFS的名字空间**。用户可以用浏览器来浏览HDFS的名字空间和查看文件的内容。

##### 15：文件的删除和恢复

- 当用户或应用程序删除某个文件时，这个文件并没有立刻从HDFS中删除。实际上，**HDFS会将这个文件重命名转移到/trash目录**。只要文件还在/trash目录中，该文件就可以被迅速地恢复。文件在/trash中保存的时间是可配置的，当超过这个时间时，Namenode就会将该文件从名字空间中删除。删除文件会使得该文件相关的数据块被释放。

##### 16：减少副本系数

- 当一个文件的副本系数被减小后，Namenode会选择过剩的副本删除。下次心跳检测时会将该信息传递给Datanode。Datanode遂即移除相应的数据块，集群中的空闲空间加大。

















