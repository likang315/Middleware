### 分布式集群

------

[TOC]

##### 01：空集群

- 一个节点(node)就是一个Elasticsearch实例，而一个集群(cluster)由一个或多个节点组成，它们具有相同的 cluster.name ，它们协同工作，分享数据和负载。当加入新的节点或者删除一个节点时，集群就会感知到并平衡数据。
- 集群中一个节点会被选举为主节点(master),它将**临时管理集群级别的一些变更**，例如新建或删除索引、增加或移除节点等。主节点不参与文档级别的变更或搜索，这意味着在流量增长的时候，该主节点不会成为集群的瓶颈。
- 可以与集群中的任何节点通信，包括主节点。**每一个节点都知道文档存在于哪个节点上，它们可以转发请求到相应的节点上。我们访问的节点负责收集各节点返回的数据，最后一起返回给客户端**。

##### 02：集群健康（cluster health）

- 集群健康有三种状态： green 、 yellow 或 red 。
  - green：所有主要分片和复制分片都可用
  - yellow：**所有主要分片可用，但不是所有复制分片都可用**
  - red：不是所有的主要分片都可用
- GET /_cluster/health
  - 查看集群健康

##### 03：分片(shard)

- **是一个最小级别工作单元(worker unit),它只是保存了索引中所有数据的一部分，分片可以想象成**数据的容器**。文档存储在分片中，然后**分片分配到你集群中的节点上**。当你的集群扩容或缩小，ES将会自动在你的节点间迁移分片，以使集群保持平衡。**
- **分片分为：**
  - 主分片(primary shard)或者是复制分片(replica shard)**。**
  - **你索引中的**每个文档属于一个单独的主分片**，所以主分片的数量决定了索引最多能存储多少数据，理论上主分片能存储的数据大小是没有限制的；**
- **复制分片只是主分片的一个副本**，它可以**防止硬件故障导致的数据丢失，同时可以提供读请求**。
- 当索引创建完成的时候，主分片的数量就固定了，但是复制分片的数量可以随时调整，系统会自动为每个主分片分配一个对应的复制分片；
  - unassigned_shards：集群健康，系统自动分配的复制分片还没有分配给节点，因为在同一个节点上保存相同的数据副本是没有意义的，如果这个节点故障，数据副本也会丢失；

##### 04：避免故障

- 为了避免**单点故障**，我们可以启动另一个节点，只要第二个节点与第一个节点有相同的 cluster.name （./config/elasticsearch.yml 文件），它就能**自动发现并加入第一个节点所在的集群**。
- **分片重新分配以平衡负载**：多节点时，主分片分配在不同的节点上，主节点对应的复制节点也被分配到和主节点不在同一个节点的的其他节点上；
- 保证集群是高可用的；

##### 05：扩展

###### 横向扩展【增加节点】

- 分片本身就是一个完整成熟的搜索引擎，它可以**使用单一节点的所有资源**。使用这6个分片（3个主分片和三个复制分片）我们可以扩展最多到6个节点，每个节点上有一个分片，这样就可以100%使用这个节点的资源了。

###### 纵向扩展【增加分片数】

- 写请求：取决于主分片的数量；
- 读请求：取决于主分片数和复制分片的总数量。数据越冗余，搜索性能越高；
  - 若只是有更多的复制分片在同样数量的节点上并不能提高我们的性能，大部分请求都聚集到了分片少的节点，导致一个节点吞吐量太大，反而降低性能。
- 区别出：我们可以承受几个结点故障，而不导致数据丢失；

##### 06：应对故障

- Elasticsearch可以应对节点失效，通过让我们继续尝试解决；
- 处理措施：首先**选举出主节点**，然后丢失的两个主分片的完整拷贝在其他节点上还存在，所以新主节点的第一件事是**提升这些在 Node 2 和 Node 3 上的分片的副本为主分片**，集群健康回到 yellow 状态。这个提升是瞬间完成的，当重启 Node 1节点时 ，集群会**重新分配分片**，如果 Node 1 依旧有旧节点的拷贝，它将会尝试再利用它们，它**只会复制在故障期间数据变更的部分**。







