### 保证消息的可靠性

------

[TOC]

##### 01：可靠性保证

- 指系统在各种不同的环境中会保持行为的一致性，是一个全局性的概念；
- Kafka 的**复制机制和分区多副本架构**是 Kafka 可靠性保证的核心。
- Kafka 的保证机制，从以下三个角度分析；
  - producer
  - broker
  - consumer

##### 02：Broker 配置（复制）

###### 复制系数

- default.replication.factor：在 broker 级别，可以通过其来设置自动创建的主题的复制系数（partition 副本）；
  - 默认：3；

###### 不彻底的首领选举

- unclean.leader.election.enable：只能在 broker 级别（实际上是在集群范围内）配置，它的**默认值是 false。**
- 如果在首领不可用时**其他副本都是不同步的**，该怎么办呢
  - 默认情况下，不允许不同步副本成为首领，因为它可以保证数据不丢失；
  - 如果**允许不同步副本成为首领**，那么就要承担丢失数据和消费者读取到**不一致的数据**的风险。如果**不允许它们成为首领，那么就要接受较低的可用性（没有分区首领了）**，因为必须等待原先的首领恢复到可用状态。

######  最少同步副本

- min.insync.replicas：可以配置在 topic 级别和 broker 级别。
- 一条消息最少要被写入多少副本之后才被认为是已提交的；

###### 保持副本同步

- zookeeper.session.timeout.ms：允许 broker 不向 ZooKeeper 发送**心跳的时间间隔**，如果超过这个时间不发送心跳，则 ZooKeeper 会认为 broker 已经“死亡”，并将其从集群中移除。
  - 默认： 18 s
- replica.lag.time.max.ms：如果一个副本未能在**指定的时间内从首领复制数据**或赶上首领，那么它将变成不同步副本。
  - 默认：30 s

###### 持久化到磁盘

- 使消息还没有被持久化到磁盘上，Kafka 也可以向生产者发出确认，这取决于已接收到消息的副本的数量。Kafka 会在重启之前和关闭日志片段（默认 1 GB 大小时关闭）时将消息刷盘；
- flush.messages：用于控制未同步到磁盘的最大消息数量；
- flash.ms：用于控制同步频率；

##### 03：生产者保证可靠性

- 发送确认
  - acks=2
  - 已提交的消息；
- 生产者重试参数：delivery.timeout.ms
  - LEADER_NOT_AVAILABLE：可重试错误
  - INVALID_CONFIG：不可重试错误，需要生成方手动处理；

##### 04：消费者保证可靠性

- auto.offset.reset：当没有偏移量（比如在消费者首次启动时）或请求的偏移量在 broker 上不存在时，消费者该作何处理；
- enable.auto.commit：是否自动提交，无法控制应用程序可能重复处理的消息的数量；
- auto.commit.interval.ms：自动提交频率，默认每 5 秒提交一次；

##### 05：Exactly-Once（精确一次性语义）

- **Exactly-Once**：一种消息传递或数据处理的语义，表示**确保每条消息仅被处理一次**，不会出现重复处理或丢失处理的情况。
  - 幂等生产者：避免因重试导致的消息重复；
  - 事务语义：保证流式处理应用程序中的精确一次性处理；

###### 幂等生产者

- Kafka 的幂等生产者可以自动检测并解决消息重复问题，只能解决止**因生产者自身的重试机制而导致的消息重复**。
- 如果启用了幂等生产者，那么**每条消息都将包含生产者 ID（PID）和序列号**。我们将它们与目标主题和分区组合在一起，用于唯一标识一条消息。broker 会用这些唯一标识符**跟踪写入每个分区的最后 5 条消息**。为了减少每个分区需要跟踪的序列号数量，生产者需要将 max.inflight.requests 设置更小的值，默认值是 5。
- enable.idempotence=true：启用幂等生产者；
- 如果 **broker 收到之前已经收到过的消息，那么它将拒绝这条消息，并返回错误**。生产者会记录这个错误，并反映在指标当中，但不抛出异常，也不触发告警。在生产者客户端，错误将被添加到 record-errorrate 指标当中。在 broker 端，错误是 ErrorsPerSec 指标的一部分（RequestMetrics 类型）。
- 如果 broker 收到一个非常大的序列号该怎么办？如果 broker 期望消息 2 后面跟着消息 3，但收到了消息27，那么这个时候该怎么办？在这种情况下，**broker 将返回“乱序”错误**。如果使用了不带事务的幂等生产者，则这个错误可能会被忽略。
- **生产者重启**
  - 生产者在每次初始化时都会产生一个新 ID；
  - 不同的生产者发送重复的消息，因为是不同的PID；
- **broker 故障**
  - 每次生成新消息时，**首领都会用最后 5 个序列号更新内存中的生产者状态**。每次从首领复制新消息时，**跟随者副本都会更新自己的内存（同步序列号）**。当跟随者成为新首领时，它的内存中已经有了最新的序列号。

###### 事务

- 为保证 Streams 应用程序的正确性，Kafka 中加入了事务机制。
- 事务是如何保证精确一次性的（**原子多分区写入**）
  - 结果会被写入**输出主题**，偏移量会被写入 **consumer_offsets 主题**。如果可以打开一个事务，向这两个主题写入消息，如果两个写入操作都成功就提交事务，如果不成功就中止，并进行重试。

- **僵尸**：一个“死亡”但不知道自己已经“死亡”的消费者被称为“僵尸”。
