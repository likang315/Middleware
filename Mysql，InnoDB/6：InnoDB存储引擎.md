### InnoDB：是 MySQL 从 `5.5 .8` 之后版本开始默认的存储引擎, 是第一个支持完整 ACID 特性的 事务型存储引擎



### 1：InnoDB 存储引擎体系架构：

![InnoDB体系结构.png](https://github.com/likang315/Java-and-Middleware/blob/master/6%EF%BC%9AMysql%EF%BC%8CInnoDB/InnoDB/InnoDB%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84.png?raw=true)

##### 后台线程：\

作用：1：负责刷新缓缓存池中的数据，保证缓存池中的内存缓存的是最新的数据
	   2：将以修改的数据文件刷新到磁盘文件，同时保证数据库在发生异常的情况下InnoDB能恢复到正常的运行状态

 1：Master Thread：将内存数据异步刷新到磁盘, InnoDB 的主要工作都是该线程完成. 该线程具有最高的优先级
			在DB 运行过程中主要进行两部分操作: **每秒将日志缓冲刷新到磁盘, 合并插入缓冲, 将脏页刷新到磁盘等**
 2：IO Thread：处理 IO 请求的回调
 3：Purge Thread：在事务提交的时候回收 Undo Log
 4：Page Clear Thread ：将之前版本的脏页刷新操作都放入到单独的线程中来完成

​			**脏页：把数据库读出来的数据修改，还没有刷新到磁盘上**

##### 缓冲池：

​	1：InnoDB 存储引擎是基于磁盘的,并将其中所有的记录按照页的方式进行管理. 由于CPU 和磁盘速度的鸿沟, 采用缓冲池技术来提高数据库的性能
​	2：缓存池是一块内存区域, 在 DB 读取页的时候, 首先将从磁盘读到页存放到缓存池中, 这个过程称为将页"FIX"在缓冲池中,下次再读相同页的时候先判断是否在缓冲池中. 对于写操作,首先修改缓冲池中的页, 再**以一定的频率刷新到磁盘上,**
**，而不是每次发生页修改时触发，**通过"CheckPoint 机制"，刷新会磁盘
​	3：InnoDB 中**缓冲池的大小默认为 256KB**, 使用LRU(最近最少使用)算法进行管理,InnoDB 对新读取的页会放在 midpoint  (默认5/8长度处).
​	4：重做日志缓冲: InnoDB 首先将 Redo Log 日志缓冲放入这个缓冲区, 然后以一定的频率刷新到 Redo Log 文件缓冲中

​	5：缓冲池是通过LRU进行管理的，即最频繁使用的页放在LRU列表的前端，而最少使用的页放在LRU列表的尾端，首先应最先释放LRU列表的尾端的页



### 2：InnoDB 关键特性

#### 1：Insert Buffer

​	在 InnoDB 中,主键是唯一的标识,在插入记录的顺序是按照主键递增的顺序进行.因此不需要磁盘的随机读取.在⼀般情况下, 不需要随机读取另⼀个页中的记录, 因此 InnoDB 如果采用自增主键的方式去插入速度会非常快.但与此同时,更多情况下表中除了主键以外还存在其他索引, 此时的插入顺序依然是按照主键顺序存放, 对于非聚集索引的叶子节点的插入就不再是顺序的, 此时就需要离散的访问非聚集索引页, 从而产生大量随机读取导致插入性能下降，因此对于非聚集索引的插入或者更新, 不是一次直接插入到索引页中, 而是**先判断插入的非聚集索引页是否在缓冲池中**, 如果在，直接插入, 否则先放入⼀个 Insert Buffer 对象,作为占位符，然后再以**⼀定的频率进行 Insert Buffer 和 索引叶子节点的 merge 操作**

#### 2：自适应性哈希索引

​     哈希表是⼀种非常快的查找方式, 在⼀般情况下可以在 O(1) 复杂度内完成. 而 B+ 树普边需要3-4层,意味着在磁盘上进行3-4次查询

InnoDB 会监控表上各项索引页的查询, 如果**观察到适合建立哈希索引就会行动**, 因此被称为自适应性哈希索引(Adaptive Hash Index, AHI), AHI 通过索引页构造而来, InnoDB 会根据访问的频率和模式来自动为某些热点页建立 AHI

#### 3：二次写 （double write buffer）

​     double write 分为 两部分，一部分是 double write buffer，大小为 2M，另外一部分就是物理磁盘上的共享表空间中连续的128个页，即两个区，大小同样为2M， 当缓冲池的胀业刷新时，并不直接写硬盘，而是通过**memcpy函数将脏页先拷贝到内存中的 double write buffer**，之后通过 d**ouble write buffer 再分两次写**，每次写**入1M到共享表空间的物理磁盘**上，然后马上**调用 fsync 函数**，同步磁盘



### 3：日志文件

###### 1：错误日志(ErrLog) 

​    错误日志对 MySQL 的启动, 运行, 关闭过程进行了记录, 不仅**记录了所有错误信息, 也记录了一些警告信息,** 遇到问题是应该首先查看该文件以便定位问题. 当 MySQL 不能正常启动, 或者 MySQL 在运行期间遇到的内存不足等问题都可以在其中找到详细记录

###### 2：慢查询日志(SlowLog) 

​    慢查询日志能够定位到可能存在问题的 SQL 语句, 可以**设定一个阈值, 将运行时间超过该值的 SQL 语句都记录到慢查询**日志文件中 另一个可用的参数是 log_queries_not_using_indexes, 如果SQL 语句没有使用索引, 同样会将这条 SQL 语句记录到慢查询日志文件 

###### 3：查询日志(QueryLog) 

​    查询日志记录了所有对 MySQL 请求的信息（对数据库没有修改的数据）, 不论是否得到了正确的执行. 默认文件名: 主机名.log. 

###### 4：二进制日志(BinaryLog) 

​    BinLog **记录了对 MySQL 执行更改的 (不包括SELECT 和 SHOW 等对数据本身没有修改) 的操作.** 不过若⼀个修改操作本身没有导致数据库发生变化也会被写入 Bin Log 中(如修改了一条不存在的记录). 此外, 二进制日志还包括了DB 修改操作的时间以及其他额外信息

######   Bin Log 主要用途有: 

1. **数据恢复:**某些数据的恢复需要 BinLog

  2. **集群同步:**通过复制和执行 BinLog, 使一台远程的 MySQL 从库与当前主库进行实时同步
  3. **数据同步:**不同于集群同步, 业务场景中经常需要其他组件(搜索引擎, 业务报表等)需要感知数据库的修改, 此时可以通过同步BinLog 实现



### 4：InnoDB 表存储

​	在 InnoDB 中, 表都是根据主键顺序组织存放的, 这种存储方式成为索引组织表. 每张表都有一个主键, 如果没有显式指定, InnoDB 会使用第一个非空的唯一索引, 如果没有唯一索引, InnoDB 会自动创建一个 6 字节大小的指针作为主键

![InnoDB存储.png](https://github.com/likang315/Java-and-Middleware/blob/master/6%EF%BC%9AMysql%EF%BC%8CInnoDB/InnoDB/InnoDB%E5%AD%98%E5%82%A8.png?raw=true)

###### 所有的数据被存放在一个表空间 (tablespace) 中, 表空间由 段(segment), 区(extent), 页(page) 组成.

​	**1：表空间(Tablespace)**：是 InnoDB 存储引擎逻辑存储的顶层对象,所有数据都存放在表空间. 其中包括数据, 索引, 插入缓冲, 回滚信息, 系统事务信息等
​	**2：段(Segment)**：表空间是由多个段组成的, 常见的段有**数据段, 索引段, 回滚段等**. InnoDB 由于索引组织表的特点, 
数据即索引, 索引即数据. 因此数据段是 B+ 树的叶子节点, 索引段是 B+ 树的非叶子节点
​	**3：区(Extent)**：区是由连续页组成的空间, 在任何情况下每个区的大小都为 1MB, 为了保证区中页的连续性, InnoDB 一次从磁盘申请 4-5 个区, **默认情况下 InnoDB 页的大小为 16KB, 一个区中一共有 64 个连续的页** 
​	**4：页(Page)**：是 InnoDB 磁盘理的最小单位, 默认 16KB, 常见的页有: 数据页 / undo log页 / 系统页等. 
​	**5：行(Row)**：InnoDB 中数据按行进行存放, **每页最多允许存放 16KB / 2 - 200 = 7992 行记录**

InnoDB 中页是管理数据库的最小磁盘单位,页类型为 **B-tree Node 的页存放的就是表中的实际数据**
InnoDB 数据页由一下 **7 部分组成:** 
	• File Header(文件头), 固定 38 字节,用来**记录头信息, 以及相邻页的指针** 
	• Page Header(页头), 固定 56 字节, 用来**记录数据页的状态信息**
	• Infinum 和 Suprenum Records, 虚拟的行记录, 用**来限定记录的边界**
	• User Recodes(用户记录, 即行记录) 
	• Free Space(空闲记录) 
	• Page Directory(页目录), 存放记录的相对位置, 找到 B+ 树叶⼦节点后, 再通过Page Directory 再进行二分查找 
	• File Trailer(文件结尾信息), 固定 8 字节, 用于**检测页是否已经完整地写入磁盘**



### 5：B+ 树：一个页（索引段和数据段）就是一个B+ 树，索引页

### 6：索引：

数据库对象之一，是为了提高查询效率，索引其实是就一张表，该表保存了主键与索引字段，并指向数据表中的记录，索引是对数据库表中一列或多列的值进行排序的一种结构

##### 1：聚集索引(物理索引，主键索引)

​	InnoDB 存储引擎是索引组织表, 表中数据按照主键顺序存放

聚集索引就是按照**每张表的主键构造⼀棵 B+ 树,** 同时叶子节点中存放整张表的记录数据(数据页), 聚集索引的特性决定了索引组织表中数据也是索引的一部分, 每个数据都通过一个双向链表来进行连接

一个表只能有一个聚集索引，因为一个表的物理顺序只有一种情况,并且多数情况下查询优化器都倾向于采用聚集索引, 因为可以直接在其叶子节点上找到数据

##### 2：辅助索引

辅助索引, 叶子节点不包括行记录的全部数据, **叶子节点除了包含键值以外, 每个叶子节点中还包含了一个指针, 指向聚集索引中的主键,** 然后再通过主键索引来找到一个完整的记录（存储了此索引到主键的一种映射关系）

##### 3：联合索引 

​	联合索引也是一棵 B+ 树, 不同的是联合索引的键值数量大于2 ,此外, 逻辑上和单键值的 B+ 树并没有什么区别, 键值依旧是有序的,只不过这个有序是一个前提的: **首先会按照 a 列进行排序, 此外 b 列的排序规则是在 a 相同的前提下, b 才有序**

**联合索引的规则：首先会对复合索引的最左边的，也就是第一个字段的数据进行排序，在第一个字段的排序基础上，然后再对后面第二个的字段进行排序，其实就相当于实现了类似 order by name cid这样一种排序规则**

**注意：联合索引要遵循最左前缀匹配原则，即多个主键必须依次索引**

##### 4：覆盖索引 

​	InnoDB 支持**直接从辅助索引中查询记录并返回**(如果有的话), 而不需要查询聚集索引中的记录.使用覆盖索引的好处是辅助索引不包含整行记录的所有信息, 故其大小要远小于聚集索引, 因此可以减少大量的 IO 操作

此外, 在某些统计场景中, 查询优化器也会倾向于选择辅助索引去统计. 辅助索引远小于聚集索引, 选择辅助索引可以减少 IO 操作

##### 5：索引失效

​	有时候在执行 EXPLAIN 进行 SQL 语句分析的时候, 会发现优化器并没有选择索引,而是执行全表扫描.这种情况多发生于范围查找 JOIN 连接等场景


###### 1：联合索引的使用不符合最左前缀匹配原则

###### 2：OR 条件连接的多个条件中有不走索引的字段

###### 3：LIKE 查询前缀模糊匹配

4：InnoDB 出现隐式类型转换(varchar -> bigint)

###### 5：InnoDB 评估使用全表扫描比走索引更快 

###### 6：无法通过索引获取全部数据, 需要从主索引中进行大量的随机读

###### 7：在联合索引中不能有列的值为NULL，如果有，那么这一列对联合索引就是无效的，所以用特殊值代替



### 索引的效率

**查找效率：**因为索引表按照索引的字段是有序排列的，是一种有序度，而不是随机读

**插入，删除效率低：**当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度，而且索引也是非常消耗内存的

解决方式：

1：进行大量插入时，可以先删除索引，再插入，完成后再加索引

2：通过Insert Buffer，插入或者更新, 不是一次直接插入到索引页中, 而是**先判断插入的非聚集索引页是否在缓冲池中**, 如果在，直接插入, 否则先放入⼀个 Insert Buffer 对象,作为占位符，然后再以**⼀定的频率进行 Insert Buffer 和 索引叶子节点的 merge 操作**

3：读表和写表分离



### 索引的使用策略

1：**什么列要使用索引**:

- 表的主键、外键必须有索引

- 经常作为**查询条件在WHERE或者ORDER BY 语句中出现的列要建立索引**

- 作为**排序的列**要建立索引

- **索引应该建在小字段上**，对于大的文本字段甚至超长字段，不要建索引

  

2：**什么列不要使用索引？**

- **经常增删改的列**不要建立索引
- 有**大量重复的列**不建立索引
- **表记录太少**不要建立索引



### 6：索引的类型

​	INDEX 普通索引：允许出现相同的索引内容
​	UNIQUE 唯一索引：不可以出现相同的值,可以有NULL值
​	PRIMARY KEY 主键索引：不允许出现相同的值,且不能为NULL值,一个表只能有一个primary_key索引
​	fulltext index 全文索引

######   索引的添加

​		CREATE INDEX：只能对表增加普通索引或UNIQUE索引
​		CREATE INDEX index_name ON table_name (column_list)
​		CREATE UNIQUE INDEX index_name ON table_name (column_list)

```sql
ALTER TABLE 表名 ADD 索引类型 （unique,primary key,fulltext,index）'索引名'（字段名，字段名）
ALTER TABLE 'table_name' ADD INDEX 'index_name' ('column_list')-索引名,可要可不要;如果不要,当前的索引名就是该字段名
```

######   索引的删除

```sql
ALTER TABLE 'table_name' DROP INDEX 'index_name'
ALTER TABLE 'table_name' DROP PRIMARY KEY -- 删除主键索引,注意主键索引只能用这种方式删除
```

######   索引的查看

​	show index from tablename \G;

######   强制使用某种索引

​	FORCE INDEX （索引字段名）



### 7：锁：数据库系统区别于文件系统的⼀个关键特性，用于管理对共享资源的并发访问

InnoDB 会在行记录上加锁，同时也会在内部其他地方使用，如LRU列表，InnoDB提供**一致性的非锁定读,行锁**，可以同时**保证并发性和一致性**

InnoDB 实现了一下两种标准的行级锁

###### 1：共享锁：事务读一行数据，读锁 

###### 2：排他锁：事务删除或更新一行数据 ，写锁（每次修改操作，默认时排它锁）

   此外, **InnoDB 支持多粒度锁定**, 允许事务在行级别和表级别同时存在, 因此引出了意向锁(Intention Lock)
   意向锁意味着事务希望在更细粒度上进行加锁

######  3：表锁：操作对象是数据表，没有走索引，加的是表锁

Mysql大多数锁策略都支持(常见mysql innodb)，是系统开销最高但并发性最低的一个锁策略。事务t对整个表加读锁，则其他事务可读不可写，若加写锁，则其他事务增删改都不行

######  4：行级锁：操作对象是数据表中的一行

是MVCC技术用的比较多的，但在MYISAM用不了，行级锁用mysql的储存引擎实现而不是mysql服务器。但行级锁对系统开销较大，处理高并发较好

InnoDB 行锁 是 **通过给索引上的索引项加锁来实现的**，InnoDB这种行锁实现特点意味着：**只有通过索引条件检索数据，InnoDB才使用行级锁（自动加），否则，InnoDB将使用表锁**

由于MySQL的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是**访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的**

###### 5：间隙锁（Next-Key 锁）

当我们**用范围条件而不是相等条件检索数据**，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；**对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，**InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）

**使用间隙锁的目的：**一方面是为了**防止幻读**，以满足相关隔离级别的要求，另外一方面，是**为了满足其恢复和复制的需要**

使用范围条件检索并锁定记录时，InnoDB这种**加锁机制会阻塞符合条件范围内键值的并发插入**



**自动加锁：**在InnoDB中，insert,update,delete 等语句执行时都会**自动加解锁**，修改操作的 X 锁会持有到事务结束，效率高很多

**手动加锁：**select .... from table where 索引条件 **for update**，在SQL语句中手动加锁，是一种悲观锁

乐观锁：通过版本号，当前版本如果对应上了，就更新数据，否则就不会更新成功



### 8：一致性非锁定读 (consistent nonblocking read) （MVCC ：多版本并发控制技术）

​	指InnoDB 通过**多行版本控制的方式来读取当前执行时间数据中的数据**.如果当前数据正在执行写操作,这时读取操作不会因此阻塞而是去读取⼀个快照数据(副本)，快照数据就是当前行数据的历史版本,有多个版本

每行记录可能有多个版本, READ COMMITTED 和 REPEATABLE READ 下, InnoDB 都会使用一致性非锁定读, 但方式不同：
		READ COMMITTED 下，一致性非锁定读总是读取被锁定**行的最新一份快照（快照读）**
		REPEATABLE READ 下，一致性非锁定读总是读取事务**开始时的行版本数据（当前读）**

MVCC 通过维护多版本数据，保证一个读事务永远不会被阻塞，对象 P 维护有多个版本，**每个版本会有一个读时间戳**（Read TimeStamp, RTS）和 **写时间戳（Write TimeStamp, WTS）**，事务 Ti 读对象 P 的最新版本，该版本早于事务 Ti 的读时间戳 RTS(Ti)

#### MVCC 优缺点

代替了行锁，实现了对读的非阻塞，读不加锁，读写不冲突，缺点是每行记录都需要额外的存储空间，需要做更多的行维护和检查工作

#### purge：undo log 每一行都记录了一个版本

由于旧数据并不真正的删除，所以必须对这些数据进行清理，innodb 会开启一个后台线程执行清理工作，具体的规则是将删除版本号小于当前系统版本的行删除，这个过程叫做 purge



### 9：锁造成的问题，都是写的时候不加锁造成的

**​1:更新丢失：**双写，解决办法是一个一个地写

###### 	1：回滚丢失：一个事务写的时候成功的时候，另一个事务写失败了，导致了回滚，读已提交解决

###### 	2：覆盖丢失：一个成功的事务，覆盖了另一个成功的事务的结果，可重复读解决

**2:脏读：**读到未提交的数据，解决办法是写完之后再读

**3:不可重复读：**同一事务的两次读操作取回不一致的结果,解决办法是写完再读

假如A在取款事务的过程中，B往该账户转账100，A两次读取的余额发生不一致

**4:幻读：**新增加了几条数据，前后读取条数不一致，解决办法是写完再读



### 9：死锁检测 (dead lock)

   解决死锁: 

###### 	1：超时检测:

 设置一个阈值,当任意一方等待时间超过预设的阈值时, 其中⼀个事务回滚 

###### 	2：for-graph 主动检测：

通过“等待获取的锁” 和 “等待获取该锁的事务”, 构造出⼀张有向图，如果图中存在回路, 就代表存在死锁, 一旦  发现回路, 就将其中一个回滚, 另⼀个事务就得以继续执行被回滚的事务会返回"dead lock"



### 10：事务：指的是满足 ACID 特性的任意一种操作

ACID：原子性(Atomic),一致性(Consistency)（数据库的角度）,隔离性(Isolation),和持久性（Durabiliy）

事务的隔离性由锁来实现, 原子性, 一致性和和 Undo Log 来完成，持久性由 Redo Log 实现
Redo Log 用于保障已提交事务的 ACID 特性, Undo log 用于保障未提交的事务不会对数据库的ACID 特性产生影响

### 11：事务实现

#####   1：Redo Log(重做日志）用来实现事务中的持久性, 由两部分组成：

​	内存中的重做日志缓冲(redo log buffer) 
​	磁盘中的重做日志文件(redo log file) 
 当事务提交的时候, 必须先将该事务的所有日志写入到磁盘中的重做日志文件进行持久化, 待事务提交结束才算完成

#####   2：Undo Log（回滚日志）记录了事务的行为, 可以很好的对页进行 "重做" 操作, 但事务有时候需要进行回滚

此时就需要undo log, redo log 存放在数据库内部的回滚段中, 位于共享表空间 

重做日志的主要工作是将数据库逻辑地恢复到原来的样子, 但数据结构和页本身在回滚之后可能和事务开始前不太相同, 因为与此同时有大量的并发事务存在, 不能简单的将一个页回滚到事务开始时的样子, 否则会影响其他事务，恢复行记录

Undo Log 的另一个功能是 MVCC，当需要读取的记录已经被其他事务加锁的时候, 当前事务可以通过 undo 读取之前的版本, 以此实现一致性非锁定读

### 12：事务隔离级别

​	隔离级别有 4 个，由低到高依次为 Read uncommitted、Readcommitted、Repeatable read、Serializable
​	最终解决了更新丢失，脏读，不可重复读，幻读
​	MySQL 的默认隔离级别：Repeatable read

###### 项目中一般用，读已提交 作为 默认的隔离级别

###### 主从复制的 bin log，有三种格式

1：statement：记录修改的Sql语句

2：row：记录每行记录实际数据的变更

3：mixed：两种混合模式

在statement格式下，读已提交这种隔离级别的主从复制，会出现错误的（master上执行先删后插，slave执行的是先插后删），会导致主从不一致，因此**用可重复读，在级别下引入了间隙锁**，或者选用 **row作为binlog的格式**

###### 若使用串行化，事务一个一个按顺序执行，每次读都会加锁，导致快照读失效

在读已提交的情况下，出现不可重复读的问题是可以接受的，因为毕竟你的数据已经提交了，读出来本身是没有太大区别的

### 13：回滚段

​	事务操作时，回滚段包含undo log，可以roolback ,如果事务提交, 回滚段中的 undo log 可以删除

### 14：当前读 和 快照读

在RR级别下，**快照读是通过MVVC(多版本控制)和undo log来实现的**，**当前读是通过加record lock(记录锁)和gap lock(间隙锁)来实现的**

**在 rr 级别下：**MVCC完全**解决了重复读，但并不能真正的完全避免幻读**，只是在部分利用**历史数据规避了幻读**

对于快照读，mysql使用历史数据部分避免了幻读，若需完全避免，需要手动加锁将快照读调整为当前读（mysql 不会自动加锁），然后mysql使用next-key完全避免了幻读



### 15：主从复制

![主从复制.png](https://github.com/likang315/Java-and-Middleware/blob/master/6%EF%BC%9AMysql%EF%BC%8CInnoDB/InnoDB/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6.png?raw=true)

从库生成两个线程，**一个I/O线程，一个SQL线程**

主库会把通过**bin log 记录每次修改的记录**数据，**I/O 线程**去请求 主库 的bin log，主库会生成一个 **log dump 线程**，用来给从库 i/o线程传bin log，从库将得到的 **bin log日志写Relay log（中继日志） 文件中，SQL 线程，会读取Relay log文件中的日志**，并解析成具体操作，来实现主从的数据一致

##### 1：异步复制原理 ：

主库提交事务后，立即返回客户端，它的同步是有从库的I/O线程请求才传送 Bin log 的

##### 2：半同步复制原理：

主库在执行完客户端提交的事务后不是立刻返回给客户端，而是**等待至少一个从库接收到并写到relay log中才返回给客户端**，相对于异步复制，半同步复制提**高了数据的安全性，同时它也造成了一定程度的延迟**，这个延迟最少是一个TCP/IP往返的时间

#### 主从复制优缺点：

###### 1：灾容性好，用于故障切换，和恢复数据库

###### 2：读写分离，提供查询服务

###### 缺点：

1：从库**只有一个sql Thread**，主库写压力大，复制很可能延时，通过并行复制解决

#### 主从复制方式

###### 1：一主一从

###### 2：一主多从，读是在从库读取的

###### 3：主主复制

###### 4：多主一从

###### 5：联级复制



