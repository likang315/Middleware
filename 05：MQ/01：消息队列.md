### 消息队列

------

[TOC]

##### 01：什么是消息队列

- 消息：是在两个节点间传送的数据单位；
- 消息队列：是指消息**传输过程中保存消息的容器**，消息队列在将消息从它的**源中继到它的目标时**充当中间；
- 目的：提供路由并保证消息的传递；如果发送消息时消费者不可用，消息队列会保留消息，直到可以成功地传递它；

##### 02：使用消息队列的优势

1. ###### 解耦

   - 将消息写入消息队列，需要消息的系统自己从消息队列中订阅，从而系统不需要做任何修改。
   - ![](https://github.com/likang315/Middleware/blob/master/MQ/photos/%E8%A7%A3%E8%80%A6.png?raw=true)

2. ###### 异步

   - 传统的方式，一些实时性要求不高的任务，已同步的方式运行，耗时太长，如果将消息写入消息队列，非必要的业务逻辑以异步的方式运行，加快响应速度。
   - 下单时，成长值计算；
   - ![](https://github.com/likang315/Middleware/blob/master/MQ/photos/%E5%BC%82%E6%AD%A5.png?raw=true)

3. ###### 削峰

   - 并发量大的时候，所有的请求直接怼到机器上，造成服务不可用，系统慢慢的按照机器能处理的并发量，从消息队列中慢慢**拉取消息**。在生产中，这个**短暂的高峰期积压**是允许的。
   - ![](https://github.com/likang315/Middleware/blob/master/MQ/photos/%E5%89%8A%E5%B3%B0.png?raw=true)

##### 03：使用消息队列的弊端

1. 系统的可用性降低； 
   - 假如消息队列突然挂了，会丢失数据；
2. 系统的复杂性不增加；
   1. 如何保证消息不会被重复消费，一致性问题等；

##### 04：消息队列的选型

| 特性       |                      ActiveMQ                       |                           RabbitMQ                           |                           RocketMQ                           |                            Kafka                             |
| ---------- | :-------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| 开发语言   |                        java                         |                            erlang                            |                             java                             |                            scala                             |
| 时效性     |                        ms级                         |         微秒级, 这是rabbitmq的一大特点,延迟是最低的          |                             ms级                             |                        延迟在ms级以内                        |
| 消息可靠性 |                有较低的概率丢失数据                 |                     一般情况不会丢失消息                     |             经过参数优化配置，消息可以做到0丢失              |           **经过参数优化配置，消息可以做到0丢失**            |
| 可用性     |            高，基于主从架构实现高可用性             |                 高，基于主从架构实现高可用性                 |                      非常高，分布式架构                      | 非常高，**kafka是分布式的**，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 |
| 功能支持   | MQ领域的功能极其完备，版本release不活跃，不建议使用 | 基于erlang开发，所以并发能力很强，性能极其好，延时很低，不能解读源码，但是社区非常活跃，可以考虑 | MQ功能较为完善，还是分布式的，扩展性好，Ali的，可以自己定制功能 | **功能较为简单**，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用，是事实上的标准 |

##### 05：如何保证高可用性

1. rocketMQ
   - 通信过程：Producer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从 NameServer 获取Topic路由信息，并向提供 Topic 服务的 Broker Master 建立长连接，且定时向 Broker 发送心跳，Producer 只能将消息发送到 Broker master，但是 Consumer 则不一样，它同时和提供 Topic 服务的 Master 和 Slave建立长连接，既可以从 Broker Master 订阅消息，也可以从 Broker Slave 订阅消息。
   - ![](https://github.com/likang315/Middleware/blob/master/MQ/photos/rocketMQ.png?raw=true)

2. kafka
   - 一个典型的Kafka集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。
   - ![](https://github.com/likang315/Middleware/blob/master/MQ/photos/kafkaMQ.png?raw=true)

##### 06：如何保证消费的可靠性传输【消息丢失】

- 每种MQ都要从三个角度来分析:

  1. **生产者弄丢数据**；
     - Kafka 异步发送消息，不论发送成功还是失败，broker都会返回一个响应告知producer 进行处理；
     - RabbitMQ提供**transaction和confirm模式**来确保生产者不丢消息。
     - **transaction机制**就是说，发送消息前，开启事物(channel.txSelect())，然后发送消息，如果发送过程中出现什么异常，事物就会回滚(channel.txRollback())，如果发送成功则提交事(channel.txCommit())，然而缺点就是吞吐量下降了。
     - 一旦channel进入**confirm模式**，所有在该信道上面发布的消息都将会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，rabbitMQ就会**发送一个Ack给生产者**(包含消息的唯一ID)，这就使得生产者知道消息已经正确到达目的队列了，如果rabiitMQ没能处理该消息，则会**发送一个Nack**消息给你，可以进行重试操作。
  2. **消息队列弄丢数据**；
     - **开启持久化磁盘**的配置；
     - 这个持久化配置可以和confirm机制配合使用，你可以在**消息持久化磁盘后，再给生产者发送一个Ack信号**。这样，如果消息持久化磁盘之前，rabbitMQ阵亡了，那么生产者收不到Ack信号，生产者会自动重发；
  3. **消费者弄丢数据**；
     - 消费者丢数据一般是因为采用了**自动确认消息模式**；
     - 这种模式下，消费者会自动确认收到信息。这时MQ会立即将消息删除，这种情况下如果消费者出现异常而没能处理该消息，就会丢失该消息，**解决方案：手动确认消息**；
   - offset：指的是kafka的topic中的每个消费组消费的下标。简单的来说就是一条消息对应一个offset下标，每次消费数据的时候如果commit offset，那么下次消费就会从提交的offset加一那里开始消费；

##### 07：如何保证消息不被重复消费【重复消费】

- 正常情况下，消费者在消费消息时候，消费完毕后，会发送一个确认信息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除。
- 只是不同的消息队列发送的确认信息形式不同,例如**RabbitMQ是发送一个ACK确认消息，RocketMQ是返回一个CONSUME_SUCCESS成功标志，kafka实际上有个offset的概念**；
- 简单说一下,就是每一个消息都有一个offset，kafka消费过消息后，需要提交offset，让消息队列知道自己已经消费过了。那造成重复消费的原因?，就是因为**网络传输等等故障，确认信息没有传送到消息队列**，导致消息队列不知道自己已经消费过该消息了，再次将该消息分发给其他的消费者；
- 解决方式【消息ID幂等】
  1. 拿到这个消息做数据库的insert操作。那就容易了，**给这个消息做一个唯一主键**，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据；
  2. **做消费记录**。以redis为例，给消息分配一个全局id，只要消费过该消息，将<id，message>以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录即可。

##### 08：如何保证消息的顺序性

- 通过某种算法，将需要保持先后顺序的消息放到同一个消息队列中**(kafka中就是partition)**，然后只用一个消费者去消费该队列即可，不过吞吐量太差；
- 如果为了吞吐量，有多个消费者去消费时，一定要**保证消息入队有序即可，出队的顺序交给消费者自己去保证**；
- kafka 相同的key会发送到同一个partition，只要**该分区只有一个消费者线程**即可保证有序；

##### 09：消费者消费方式

1. **异步方式**：**push** 创建监听器监听消费，当有消费被push过来时，自动触发消费，**导致洪峰**；
2. **同步方式**：**pull** 的方式去拉取消息消费，阻塞线程一直拉取消息；

##### 10：MQ积压大量消息

1. 恢复消费者消费能力，然后**临时紧急扩容**，增大消费能力；

##### 11：消息队列的存储方式

1. **分布式KV存储**
   - 这类 MQ 一般会采用诸如 LevelDB 、RocksDB 和 Redis 来作为消息持久化的方式；
2. **文件系统**
   - 消息**刷盘至所部署机器的文件系统**来做持久化；
   - 例如：Kafka；
3. **关系型数据库 DB**
   - MQ—ActiveMQ（默认采用的KahaDB做消息存储）可**选用 JDBC 的方式**来做消息持久化，通过简单的 XML 配置信息即可实现JDBC消息存储；
   - 普通关系型数据库（如 MySQL ）在**单表数据量达到千万级别**的情况下，其 IO 读写性能往往会出现瓶颈；




